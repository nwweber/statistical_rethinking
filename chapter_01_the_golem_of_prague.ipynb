{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 statistical golems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* models neither true nor false, constructs engineerd for some purpose\n",
    "* follow direct instructions, no insight or wisdom on their part. machines.\n",
    "* a lot of models -> specialized machines for different purposes\n",
    "* statistics in this sense more engineering than mathematics or science\n",
    "* single method for building, refining and critiquing. however, not commonly taught. instead what's in books is often list of final products, i.e. models, without showing common principles they are made from. confusing and leaves no room for reasoning when trade-offs and judgement are required\n",
    "* Toolbox of existings tests/models not good enough for innovative research. inflexible = only fit limited research contexts. fragile = fail in unpredictable ways in new contexts\n",
    "* Especially problematic for innovative research as existing models have not been evaluated here\n",
    "* Rethink statistical inference as a set of strategies instead of pre-made tools. Learn set of principles to engineer new special-purpose statistical procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 statistical rethinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* need to understand how golem/model processes information to interpret output\n",
    "* need to understand how models realte to hypotheses and natural mechanisms of interests\n",
    "* greatest obstacle: belief that \"objective of statistical inference is to test null hypothesis\"\n",
    "* based on 'folk' version of Popper: science advances through falsification, thus stats needs to falsify\n",
    "* deductive falsification impossible in nearly every scientific context. two main reasons:\n",
    "* hypotheses are not models. many models correspond to same hypothesis and many hypotheses correspond to single model\n",
    "* measurements matter. even if model is good, measurements might be wrong\n",
    "* scientific method cannot be reduced to statistical procedure, thus statistical methods should not pretend. stat evidence is part of messy scientific process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hypotheses are not models\n",
    "* impossible to deduce that hypothesis is false just due to rejection of model derived from i\n",
    "* informal, vague hypothesis can have many precise process models, aspects of which get encoded into statistical models\n",
    "* one stats model may correspond to multiple process models, thus also corresponding to multiple vague hypotheses\n",
    "* makes it impossible to conclusively falsify some hypothesis\n",
    "* some way out: figure out ways in which the same process model does generate different statistical models, e.g. in distributions of another quantity. compare those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* measurements matter\n",
    "* story of black swan proving 'all swans are white' wrong\n",
    "* reality not this easy. often measurements unclear, especially at boundary of knowledge. also more often concerned with degree of existence instead of absolute yes/no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* falsification is consensual, not logical. scientific ommunities argue about interpretation of evidence until consensus is reached. messy process. sometimes misrepresented as tidy fable of falsification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 three tools for golem engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* all formal systems are like models\n",
    "* even procedures that claim to be free of assumptions do have assumptions and are a kind of model\n",
    "* all statistical tests are also models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. bayesian data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bayesian = particular interpretation of probability\n",
    "* bayesian inference = counting the numbers of ways things can happen according to assumptions\n",
    "* more ways = more plausible\n",
    "* probability theory = calculus for counting. thus: use prob theory to represent plausibility, both for countable events in real world and theoretical constructs like params\n",
    "* after accepting this all else is logical\n",
    "* contrasted to frequentist approach. fr. app. requires: all probs must be defined by connection to countable events and their frequencis in very large samples\n",
    "* thus: frequentist uncetainty based on imaginary resampling of data. what would data look like if we repeated measurement many times?\n",
    "* thus: parameters and models cannot have prob distributions, only measurements can\n",
    "* distribution of measurements: sampling distribution\n",
    "* resampling never done, and actually absurd: cannot resample distribution of birds in andes\n",
    "* assumption of sampling distribution = fantasy. at the same time, assumption of prior = fantasy\n",
    "* bayesian models treat randomness as a property of information, not of the world. nothing in the world is random. if we had total information, we could predict exactly. not the tossed coin is random, but it's the model doing the prediction.\n",
    "* all of the above description of bayesian analysis: no invokation of subjective belief. purely logical procedure for information processing\n",
    "* using this procedure as a normative description of rational belief = bayesianism.\n",
    "* not subject of this book, not advocated\n",
    "* many different axiomatizations of bayesian probability exist, based on different arguments for why they make sense. these lead to different versions of bayesian probability. this book: Laplace-Jeffreys-Cox-Jaynes interpretation\n",
    "* what does it mean to take the sqr root of a negative number? what does it mean to take the limit as something approaches infity? many different interpretations possible. by themselves, mathematical entities don't necessarily mean anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. multilevel models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* it's turtles/parameters all the way down\n",
    "* models have parameters\n",
    "* parameters can in turn be inferred\n",
    "* any particular parameter can be regarded as placeholder for a missing model\n",
    "* that model can be plugged into the original model\n",
    "* multilevel = hierarchical = random effects = varying effects = mixed effects model\n",
    "* reasons for using multilevel models:\n",
    "* 1: adjust for repeat sampling. more than one observation arised from same individual, unit, location or time\n",
    "* 2: adjust estimates for imbalance in sampling. some individuals, times, ..., are sampled more than others\n",
    "* 3: study variation. model variation explicitly, helpful if research question deals with variation among individuals or other groups within data\n",
    "* 4: avoid averaging. preserve uncertainty in original, un-averaged data. in single-level models sometimes variables get averaged for regression analysis, removing their uncertainty.\n",
    "* applicable always when there are clusters/groups in measurements which react differently to treatment, e.g. different schools, cities, times, ...\n",
    "* scope goes beyond this, many others can be seen as multilevel models: imputation, measurement error, factor analysis, some time series models, ...\n",
    "* grasping multilevel models can lead to perspective shift. single level models can be seen as mere components of multi level models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3. model comparison and information criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* goal of information criteria: compare structually different models on future predictive accuracy\n",
    "* information criteria themselves are models and rely on assumptions\n",
    "* develop their measure of accuracy from infromation theory\n",
    "* allow for comparison multiple non-null models to the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this chapter: argued for rethinking of approach to statistics and to science. to support this approach. learn these tools: bayesian data analysis, multilevel model, information-theoretic model comparison\n",
    "* rest of the book:\n",
    "* 1: chs 2&3 lay foundation (lay a bayesis :P). introduce bayesian inference and basic tools for bayes calculations\n",
    "* 2: chs 4, 5, 6, 7: multiple linear regression, model complexity, overfitting, information theory\n",
    "* 3: chs 8, 9, 10, 11: GLMs, MCMC for fitting non-linear models, maximum entropy for designing models\n",
    "* 4: chs 12, 13, 14: multilevel models: linear + generalized linear, specialised forms dealing with measurement error, missing data, spatial correlation through gaussian processes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 (no Spark)",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
